{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN_13.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# connect with google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6ZfHj4XkcTe",
        "outputId": "04497417-ed5f-4838-be83-63702c98871e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "7JLsDjvTkqUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator Class\n",
        "\n",
        "def discriminator_conv(in_channel, out_channel, kernel_size=3, stride=2, padding=1, batch_norm=True, bias=False):\n",
        "    layers = [nn.Conv2d(in_channel, out_channel, kernel_size, stride=stride, padding=padding, bias=bias)]\n",
        "\n",
        "    if batch_norm:\n",
        "        layers.append(nn.BatchNorm2d(out_channel))\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, number_of_channel, discriminator_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.disc_conv1 = discriminator_conv(number_of_channel, discriminator_dim, kernel_size=4, stride=2, padding=1, batch_norm=False)\n",
        "        self.disc_conv2 = discriminator_conv(discriminator_dim, discriminator_dim * 2, kernel_size=4, stride=2, padding=1, batch_norm=True)\n",
        "        self.disc_conv3 = discriminator_conv(discriminator_dim * 2, discriminator_dim * 4, kernel_size=4, stride=2, padding=1, batch_norm=True)\n",
        "        self.disc_conv4 = discriminator_conv(discriminator_dim * 4, discriminator_dim * 8, kernel_size=4, stride=2, padding=1, batch_norm=True)\n",
        "\n",
        "        self.disc_conv5 = discriminator_conv(discriminator_dim * 8, 1, kernel_size=4, stride=1, padding=0, batch_norm=False)\n",
        "\n",
        "\n",
        "    def forward(self, mzg):\n",
        "        out = F.leaky_relu(self.disc_conv1(mzg), inplace=True, negative_slope=0.2)\n",
        "        out = F.leaky_relu(self.disc_conv2(out), inplace=True, negative_slope=0.2)\n",
        "        out = F.leaky_relu(self.disc_conv3(out), inplace=True, negative_slope=0.2)\n",
        "        out = F.leaky_relu(self.disc_conv4(out), inplace=True, negative_slope=0.2)\n",
        "\n",
        "        out = torch.sigmoid(self.disc_conv5(out))\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "qJ4gZE1lk5sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator Class\n",
        "\n",
        "def generator_conv(in_channel, out_channel, kernel_size=3, stride=2,padding=1, batch_norm=True, bias=False):\n",
        "    layers = [nn.ConvTranspose2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias)]\n",
        "\n",
        "    if batch_norm:\n",
        "        layers.append(nn.BatchNorm2d(out_channel))\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, num_of_z, number_of_channel, generator_dim):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.gen_conv1 = generator_conv(num_of_z, generator_dim * 8, kernel_size=4, stride=1, padding=0, batch_norm=True)\n",
        "        self.gen_conv2 = generator_conv(generator_dim * 8, generator_dim * 4, kernel_size=4, stride=2 , padding=1, batch_norm=True)\n",
        "        self.gen_conv3 = generator_conv(generator_dim * 4, generator_dim * 2, kernel_size=4, stride=2, padding=1, batch_norm=True)\n",
        "        self.gen_conv4 = generator_conv(generator_dim * 2, generator_dim, kernel_size=4, stride=2, padding=1, batch_norm=True)\n",
        "\n",
        "        self.gen_conv5 = generator_conv(generator_dim, number_of_channel, kernel_size=4, stride=2, padding=1, batch_norm=False)\n",
        "\n",
        "\n",
        "    def forward(self, mzg):\n",
        "        out = F.relu(self.gen_conv1(mzg))\n",
        "        out = F.relu(self.gen_conv2(out))\n",
        "        out = F.relu(self.gen_conv3(out))\n",
        "        out = F.relu((self.gen_conv4(out)))\n",
        "\n",
        "        out = torch.tanh(self.gen_conv5(out))\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "zoZNo7BJlBV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# custom weights initialization called on netG and netD\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "metadata": {
        "id": "WWsWYRGnlLNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "From DCGAN Paper\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Number of workers for dataloader\n",
        "workers = 8\n",
        "\n",
        "# Batch size during training\n",
        "batch_size = 128\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this\n",
        "# size using a transformer.\n",
        "image_size = 128\n",
        "\n",
        "# Number of channels in the training images. For color images this is 3\n",
        "nc = 3  \n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 100\n",
        "\n",
        "# Size of feature maps in generator\n",
        "ngf = 64\n",
        "\n",
        "# Size of feature maps in discriminator\n",
        "ndf = 64\n",
        "\n",
        "# Number of training epochs\n",
        "num_epochs = 100\n",
        "\n",
        "# Learning rate for optimizers\n",
        "lr = 0.0002\n",
        "\n",
        "# Beta1 hyperparam for Adam optimizers\n",
        "beta1 = 0.5\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 0"
      ],
      "metadata": {
        "id": "amMoVOhblVTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "You must change CustomData class according to your dataset \n",
        "\n",
        "If you have a dataset where you can follow the classic data loading operations of Pytorch, you can use it.\n",
        "There are resources on how to load datasets that have classes in other resources\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class CustomData(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.images = os.listdir(data_dir)\n",
        "\n",
        "        self.images_len = len(self.images)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        img = self.images[item % self.images_len]\n",
        "\n",
        "        img_path = os.path.join(self.data_dir, img)\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        img = self.transform(img)\n",
        "\n",
        "        return img\n"
      ],
      "metadata": {
        "id": "I2WuALdsR0G4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        [0.5 for _ in range(nc)], [0.5 for _ in range(nc)]\n",
        "    ),\n",
        "])\n",
        "\n",
        "# Dataset\n",
        "dataset = CustomData('/content/drive/images/', transform = transform)\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "BBwijb7Vmqi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.__len__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Qe7tLcqYvMh",
        "outputId": "cdf8efcd-0473-4ad6-de55-49b01a379d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "986"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen = Generator(nz, nc, ngf)\n",
        "disc = Discriminator(nc, ndf)\n",
        "\n",
        "weights_init(gen)\n",
        "weights_init(disc)"
      ],
      "metadata": {
        "id": "9nwhWwUJmwF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6UbyCy1mzm7",
        "outputId": "86d14e73-ec95-4972-8aaa-023b430f71c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (gen_conv1): Sequential(\n",
              "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (gen_conv2): Sequential(\n",
              "    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (gen_conv3): Sequential(\n",
              "    (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (gen_conv4): Sequential(\n",
              "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (gen_conv5): Sequential(\n",
              "    (0): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "disc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14-gH96rm1JE",
        "outputId": "c7c7a573-5819-4b67-db48-0e220491bcd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (disc_conv1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  )\n",
              "  (disc_conv2): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (disc_conv3): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (disc_conv4): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (disc_conv5): Sequential(\n",
              "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt_gen = optim.Adam(gen.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "opt_disc = optim.Adam(disc.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "fixed_noise = torch.randn(32, nz, 1, 1)\n",
        "\n",
        "writer_real = SummaryWriter(f\"logs/real\")\n",
        "writer_fake = SummaryWriter(f\"logs/fake\")\n",
        "\n",
        "step = 0"
      ],
      "metadata": {
        "id": "iU6RvspOm3Ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen.train()\n",
        "disc.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fX4F0Iwam7Lu",
        "outputId": "dd55b6b9-581f-4017-c819-713a17b1446f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (disc_conv1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  )\n",
              "  (disc_conv2): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (disc_conv3): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (disc_conv4): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (disc_conv5): Sequential(\n",
              "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    # Target labels not needed! <3 unsupervised\n",
        "    for batch_idx, real in enumerate(dataloader):\n",
        "        noise = torch.randn(batch_size, nz, 1, 1)\n",
        "        fake = gen(noise)\n",
        "\n",
        "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
        "        disc_real = disc(real).reshape(-1)\n",
        "        loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
        "        disc_fake = disc(fake.detach()).reshape(-1)\n",
        "        loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
        "        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
        "        disc.zero_grad()\n",
        "        loss_disc.backward()\n",
        "        opt_disc.step()\n",
        "\n",
        "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
        "        output = disc(fake).reshape(-1)\n",
        "        loss_gen = criterion(output, torch.ones_like(output))\n",
        "        gen.zero_grad()\n",
        "        loss_gen.backward()\n",
        "        opt_gen.step()\n",
        "\n",
        "        # Print losses occasionally and print to tensorboard\n",
        "        if batch_idx % 10 == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(dataloader)} \\\n",
        "                  Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\"\n",
        "            )\n",
        "\n",
        "            with torch.no_grad():\n",
        "                fake = gen(fixed_noise)\n",
        "                # take out (up to) 32 examples\n",
        "                img_grid_real = torchvision.utils.make_grid(\n",
        "                    real[:32], normalize=True\n",
        "                )\n",
        "                img_grid_fake = torchvision.utils.make_grid(\n",
        "                    fake[:32], normalize=True\n",
        "                )\n",
        "\n",
        "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
        "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
        "\n",
        "            step += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw-ZKLswnB9i",
        "outputId": "30919f8d-1b0e-44e8-aec4-fee7c442d465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/100] Batch 0/8                   Loss D: 0.7388, loss G: 4.2369\n",
            "Epoch [1/100] Batch 0/8                   Loss D: 0.1205, loss G: 6.1221\n",
            "Epoch [2/100] Batch 0/8                   Loss D: 0.0495, loss G: 7.1965\n",
            "Epoch [3/100] Batch 0/8                   Loss D: 0.0285, loss G: 7.8416\n",
            "Epoch [4/100] Batch 0/8                   Loss D: 0.0176, loss G: 7.7707\n",
            "Epoch [5/100] Batch 0/8                   Loss D: 0.0121, loss G: 8.1196\n",
            "Epoch [6/100] Batch 0/8                   Loss D: 0.0112, loss G: 7.7669\n",
            "Epoch [7/100] Batch 0/8                   Loss D: 0.0087, loss G: 7.9247\n",
            "Epoch [8/100] Batch 0/8                   Loss D: 0.0081, loss G: 7.8798\n",
            "Epoch [9/100] Batch 0/8                   Loss D: 0.0065, loss G: 7.5958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display results with using tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/logs/real"
      ],
      "metadata": {
        "id": "Cc7wB7DgKu9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display results with using tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/logs/fake"
      ],
      "metadata": {
        "id": "C0tf9O-GKwYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify a path to save to\n",
        "PATH = \"model_DCGAN.pt\"\n",
        "\n",
        "torch.save({\n",
        "            'modelG_state_dict': gen.state_dict(),\n",
        "            'modelD_state_dict': disc.state_dict(),\n",
        "            'optimizerG_state_dict': opt_gen.state_dict(),\n",
        "            'optimizerD_state_dict': opt_disc.state_dict(),\n",
        "            }, PATH)"
      ],
      "metadata": {
        "id": "NbpLzPP0KxUI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}