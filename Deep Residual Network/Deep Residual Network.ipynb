{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ],
   "execution_count": 80,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}"
   ],
   "execution_count": 81,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data_dir = 'kflowers'\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "class_names = image_datasets['train'].classes"
   ],
   "execution_count": 82,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class_names"
   ],
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "num_classes = len(image_datasets['train'].classes)\n",
    "\n",
    "num_classes"
   ],
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_sizes"
   ],
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 500, 'val': 264}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def conv3x3(in_planes, out_planes, stride = 1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size = 3, stride = stride, padding = 1, bias = False)\n",
    "        \n",
    "def conv1x1(in_planes, out_planes, stride = 1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size = 1, stride = stride, bias = False)\n",
    "    \n",
    "class BasicBlock(nn.Module):\n",
    "    \n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self,inplanes, planes, stride = 1, downsample = None):\n",
    "        super(BasicBlock,self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.drop(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "            \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "        \n",
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, block, layers, num_classes = num_classes):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5, stride = 2, padding = 2, bias= False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size= 3, stride = 2, padding = 1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride = 1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride = 2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride = 1)\n",
    "    \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(256*block.expansion, num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode = \"fan_out\", nonlinearity = \"relu\")\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "                \n",
    "    def _make_layer(self, block, planes, blocks, stride = 1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes*block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                    conv1x1(self.inplanes, planes*block.expansion, stride),\n",
    "                    nn.BatchNorm2d(planes*block.expansion))\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes*block.expansion\n",
    "        for _ in range(1,blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ],
   "execution_count": 86,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = ResNet(BasicBlock, [2,3,2])"
   ],
   "execution_count": 91,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "num_epochs = 25 \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ],
   "execution_count": 92,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "loss_list = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "use_gpu = False\n",
    "\n",
    "total_step = len(dataloaders['train'])\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"epoch: {}/{}\".format(epoch,num_epochs))\n",
    "    print('----------')\n",
    "\n",
    "    for i, (images, labels) in enumerate(dataloaders['train']):\n",
    "        \n",
    "        # images = images.view(batch_size,3,64,64)\n",
    "        images = images.float()\n",
    " \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backward and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # train\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders['train']:\n",
    "            images, labels = data\n",
    "            # images = images.view(batch_size,3,64,64)\n",
    "            images = images.float()\n",
    "                    \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(\"Accuracy of train %d %%\"%(100*correct/total))\n",
    "    train_acc.append(100*correct/total)\n",
    "\n",
    "    # test\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders['val']:\n",
    "            images, labels = data\n",
    "            # images = images.view(batch_size,3,64,64)\n",
    "            images = images.float()\n",
    "    \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(\"Accuracy of validation %d %%\"%(100*correct/total))\n",
    "    print('\\n')\n",
    "    train_acc.append(100*correct/total)\n",
    "\n",
    "    loss_list.append(loss.item())"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "datalore": {
   "version": 1,
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "base_environment": "default",
   "packages": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}