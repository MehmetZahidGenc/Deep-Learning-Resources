{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import os"
   ],
   "execution_count": 63,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Hyper-parameters\n",
    "num_epochs = 5\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = 64\n",
    "channel_size = 3\n",
    "\n",
    "sequence_length = input_size * channel_size # input_size * input channel size = 64 * 3 => 192\n",
    "hidden_size = 128\n",
    "num_layers = 2"
   ],
   "execution_count": 74,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# data transforms\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "            transforms.Resize((input_size, input_size)),\n",
    "            transforms.ToTensor(),\n",
    "    ]),\n",
    "}"
   ],
   "execution_count": 65,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Data loaders\n",
    "\n",
    "data_directory = 'FMD2/Face Mask Dataset'\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_directory, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'validation', 'test']}\n",
    "\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "              for x in ['train', 'validation', 'test']}"
   ],
   "execution_count": 66,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'validation', 'test']}\n",
    "print(dataset_sizes)"
   ],
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{'train': 10000, 'validation': 800, 'test': 992}\n"
     ],
     "output_type": "stream"
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class_names = image_datasets['train'].classes\n",
    "print(class_names)"
   ],
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['WithMask', 'WithoutMask']\n"
     ],
     "output_type": "stream"
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "num_classes = len(image_datasets['train'].classes)\n",
    "print(num_classes)"
   ],
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "2\n"
     ],
     "output_type": "stream"
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, layer_dim, out_dim):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        self.rnn = nn.RNN(in_dim, hid_dim, layer_dim, batch_first=True, nonlinearity='relu')\n",
    "\n",
    "        self.fC = nn.Linear(hid_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hid_dim))\n",
    "\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fC(out[:, -1, :])\n",
    "        return out"
   ],
   "execution_count": 70,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = RNN(input_size, hidden_size, num_layers, num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "execution_count": 71,
   "outputs": [],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model"
   ],
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (rnn): RNN(64, 128, num_layers=2, batch_first=True)\n",
       "  (fC): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Train Part\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(dataloaders['train']):\n",
    "        model.train()\n",
    "        # Load images as tensors with gradient accumulation abilities\n",
    "        images = images.view(-1, sequence_length, input_size).requires_grad_()\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        # outputs.size() --> 100, 10\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    # Calculate Accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Iterate through validation dataset\n",
    "    for images, labels in dataloaders['validation']:\n",
    "        # Load images to a Torch tensors with gradient accumulation abilities\n",
    "        images = images.view(-1, sequence_length, input_size)\n",
    "\n",
    "        # Forward pass only to get logits/output\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Get predictions from the maximum value\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Total number of labels\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Total correct predictions\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print('Epoch: {}. Loss: {}. Accuracy: {}'.format(epoch, loss.item(), accuracy))"
   ],
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch: 0. Loss: 0.25696811079978943. Accuracy: 82.25\n",
      "Epoch: 1. Loss: 0.35765373706817627. Accuracy: 82.125\n",
      "Epoch: 2. Loss: 0.45775526762008667. Accuracy: 73.0\n",
      "Epoch: 3. Loss: 0.28813236951828003. Accuracy: 82.5\n",
      "Epoch: 4. Loss: 0.2359645962715149. Accuracy: 84.625\n"
     ],
     "output_type": "stream"
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in dataloaders['test']:\n",
    "        images = images.reshape(-1, sequence_length, input_size)\n",
    "        labels = labels\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the test images: {acc} %')"
   ],
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Accuracy of the network on the test images: 86.39112903225806 %\n"
     ],
     "output_type": "stream"
    }
   ],
   "metadata": {
    "datalore": {
     "type": "CODE",
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python"
  },
  "datalore": {
   "version": 1,
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "base_environment": "default",
   "packages": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}